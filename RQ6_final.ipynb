{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16448662\n",
      "14595260\n",
      "1 435439\n",
      "2 2684321\n",
      "3 4116282\n",
      "4 4870339\n",
      "5 3217517\n",
      "6 1107167\n"
     ]
    }
   ],
   "source": [
    "# how many tokens are in GRC\n",
    "# how many tokens are in fiction section of COCA\n",
    "\n",
    "import sqlite3, spacy\n",
    "\n",
    "grc_conn = sqlite3.connect('D:\\\\graded_readers_mwe.sqlite') # This creates the database file\n",
    "grc_c = grc_conn.cursor() # Creates a cursor\n",
    "\n",
    "grc_c.execute('SELECT COUNT(*) FROM corpus')\n",
    "print(grc_c.fetchone()[0])\n",
    "\n",
    "grc_c.execute('SELECT COUNT(*) FROM corpus WHERE f_nf = \"F\"')\n",
    "print(grc_c.fetchone()[0])\n",
    "\n",
    "erf_levels = (1,2,3,4,5,6)\n",
    "for level in erf_levels:\n",
    "    grc_c.execute('SELECT COUNT(*) FROM corpus WHERE erf_level = ?', (level,))\n",
    "    print(level, grc_c.fetchone()[0])\n",
    "\n",
    "grc_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 2-grams in GRC total ERF Level 1 : 5531\n",
      "Number of 2-grams in GRC fiction ERF Level 1 : 5478\n",
      "Number of 2-grams in GRC total ERF Level 2 : 4910\n",
      "Number of 2-grams in GRC fiction ERF Level 2 : 4869\n",
      "Number of 2-grams in GRC total ERF Level 3 : 4878\n",
      "Number of 2-grams in GRC fiction ERF Level 3 : 4948\n",
      "Number of 2-grams in GRC total ERF Level 4 : 4681\n",
      "Number of 2-grams in GRC fiction ERF Level 4 : 4741\n",
      "Number of 2-grams in GRC total ERF Level 5 : 4694\n",
      "Number of 2-grams in GRC fiction ERF Level 5 : 4851\n",
      "Number of 2-grams in GRC total ERF Level 6 : 4342\n",
      "Number of 2-grams in GRC fiction ERF Level 6 : 4856\n",
      "Number of 3-grams in GRC total ERF Level 1 : 2417\n",
      "Number of 3-grams in GRC fiction ERF Level 1 : 2399\n",
      "Number of 3-grams in GRC total ERF Level 2 : 1678\n",
      "Number of 3-grams in GRC fiction ERF Level 2 : 1750\n",
      "Number of 3-grams in GRC total ERF Level 3 : 1481\n",
      "Number of 3-grams in GRC fiction ERF Level 3 : 1590\n",
      "Number of 3-grams in GRC total ERF Level 4 : 1307\n",
      "Number of 3-grams in GRC fiction ERF Level 4 : 1394\n",
      "Number of 3-grams in GRC total ERF Level 5 : 1283\n",
      "Number of 3-grams in GRC fiction ERF Level 5 : 1422\n",
      "Number of 3-grams in GRC total ERF Level 6 : 1005\n",
      "Number of 3-grams in GRC fiction ERF Level 6 : 1300\n",
      "Number of 4-grams in GRC total ERF Level 1 : 553\n",
      "Number of 4-grams in GRC fiction ERF Level 1 : 548\n",
      "Number of 4-grams in GRC total ERF Level 2 : 251\n",
      "Number of 4-grams in GRC fiction ERF Level 2 : 265\n",
      "Number of 4-grams in GRC total ERF Level 3 : 160\n",
      "Number of 4-grams in GRC fiction ERF Level 3 : 176\n",
      "Number of 4-grams in GRC total ERF Level 4 : 122\n",
      "Number of 4-grams in GRC fiction ERF Level 4 : 134\n",
      "Number of 4-grams in GRC total ERF Level 5 : 103\n",
      "Number of 4-grams in GRC fiction ERF Level 5 : 120\n",
      "Number of 4-grams in GRC total ERF Level 6 : 70\n",
      "Number of 4-grams in GRC fiction ERF Level 6 : 99\n",
      "Number of 5-grams in GRC total ERF Level 1 : 146\n",
      "Number of 5-grams in GRC fiction ERF Level 1 : 146\n",
      "Number of 5-grams in GRC total ERF Level 2 : 31\n",
      "Number of 5-grams in GRC fiction ERF Level 2 : 34\n",
      "Number of 5-grams in GRC total ERF Level 3 : 17\n",
      "Number of 5-grams in GRC fiction ERF Level 3 : 21\n",
      "Number of 5-grams in GRC total ERF Level 4 : 12\n",
      "Number of 5-grams in GRC fiction ERF Level 4 : 11\n",
      "Number of 5-grams in GRC total ERF Level 5 : 9\n",
      "Number of 5-grams in GRC fiction ERF Level 5 : 10\n",
      "Number of 5-grams in GRC total ERF Level 6 : 6\n",
      "Number of 5-grams in GRC fiction ERF Level 6 : 7\n"
     ]
    }
   ],
   "source": [
    "# Should produce counts for the number of n-grams by ERF level\n",
    "\n",
    "# Then it should also put these out into lists. I can basically do what I'm doing, \n",
    "# just append each list of ERF words to the end with a tag for which erf level\n",
    "\n",
    "import sqlite3, math\n",
    "\n",
    "grc_conn = sqlite3.connect('D:\\\\graded_readers_mwe.sqlite') # This creates the database file\n",
    "grc_c = grc_conn.cursor() # Creates a cursor\n",
    "grc_c.execute(\"CREATE INDEX IF NOT EXISTS ngram_count_IN ON ngrams (ngram_size, total_grc_freq)\")\n",
    "grc_c.execute(\"CREATE INDEX IF NOT EXISTS ngram_count_fic_IN ON ngrams (ngram_size, total_grc_fic_freq)\")\n",
    "grc_c.execute(\"CREATE INDEX IF NOT EXISTS ngram_count_erf_one_IN ON ngrams (ngram_size, erf_one_freq)\")\n",
    "grc_c.execute(\"CREATE INDEX IF NOT EXISTS ngram_count_erf_two_IN ON ngrams (ngram_size, erf_two_freq)\")\n",
    "grc_c.execute(\"CREATE INDEX IF NOT EXISTS ngram_count_erf_three_IN ON ngrams (ngram_size, erf_three_freq)\")\n",
    "grc_c.execute(\"CREATE INDEX IF NOT EXISTS ngram_count_erf_four_IN ON ngrams (ngram_size, erf_four_freq)\")\n",
    "grc_c.execute(\"CREATE INDEX IF NOT EXISTS ngram_count_erf_five_IN ON ngrams (ngram_size, erf_five_freq)\")\n",
    "grc_c.execute(\"CREATE INDEX IF NOT EXISTS ngram_count_erf_six_IN ON ngrams (ngram_size, erf_six_freq)\")\n",
    "grc_c.execute(\"CREATE INDEX IF NOT EXISTS ngram_count_erf_one_fic_IN ON ngrams (ngram_size, erf_one_fic_freq)\")\n",
    "grc_c.execute(\"CREATE INDEX IF NOT EXISTS ngram_count_erf_two_fic_IN ON ngrams (ngram_size, erf_two_fic_freq)\")\n",
    "grc_c.execute(\"CREATE INDEX IF NOT EXISTS ngram_count_erf_three_fic_IN ON ngrams (ngram_size, erf_three_fic_freq)\")\n",
    "grc_c.execute(\"CREATE INDEX IF NOT EXISTS ngram_count_erf_four_fic_IN ON ngrams (ngram_size, erf_four_fic_freq)\")\n",
    "grc_c.execute(\"CREATE INDEX IF NOT EXISTS ngram_count_erf_five_fic_IN ON ngrams (ngram_size, erf_five_fic_freq)\")\n",
    "grc_c.execute(\"CREATE INDEX IF NOT EXISTS ngram_count_erf_six_fic_IN ON ngrams (ngram_size, erf_six_fic_freq)\")\n",
    "grc_conn.commit()\n",
    "\n",
    "genres = (\"acad\", \"blog\", \"fic\", \"mag\", \"news\", \"spok\", \"tvm\", \"web\")\n",
    "for genre in genres:\n",
    "    coca_filename = 'D:\\\\coca_' + genre + '.sqlite'\n",
    "    coca_conn = sqlite3.connect(coca_filename)\n",
    "    coca_c = coca_conn.cursor()\n",
    "    coca_c.execute(\"CREATE INDEX IF NOT EXISTS twogram_IN ON ngrams (ngram_size, wordoneID, wordtwoID)\")\n",
    "    coca_c.execute(\"CREATE INDEX IF NOT EXISTS threegram_IN ON ngrams (ngram_size, wordoneID, wordtwoID, wordthreeID)\")\n",
    "    coca_c.execute(\"CREATE INDEX IF NOT EXISTS fourgram_IN ON ngrams (ngram_size, wordoneID, wordtwoID, wordthreeID, wordfourID)\")\n",
    "    coca_c.execute(\"CREATE INDEX IF NOT EXISTS fivegram_IN ON ngrams (ngram_size, wordoneID, wordtwoID, wordthreeID, wordfourID, wordfiveID)\")\n",
    "    coca_conn.commit()\n",
    "    coca_conn.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################# Function to pull out info from COCA #####################\n",
    "def get_coca_info(n_gram, ngram_size):\n",
    "    genres = (\"acad\", \"blog\", \"fic\", \"mag\", \"news\", \"spok\", \"tvm\", \"web\")\n",
    "    genre_counts = {}\n",
    "    ngram = n_gram.split(\"_\")\n",
    "    genre_counts[\"total\"] = 0\n",
    "    for genre in genres:\n",
    "        coca_filename = 'D:\\\\coca_' + genre + '.sqlite'\n",
    "        coca_conn = sqlite3.connect(coca_filename)\n",
    "        coca_c = coca_conn.cursor()\n",
    "        if ngram_size == 2:\n",
    "            coca_c.execute(\"SELECT freq FROM ngrams \\\n",
    "                    JOIN lexicon AS L1 ON ngrams.wordoneID = L1.ID \\\n",
    "                    JOIN lexicon AS L2 ON ngrams.wordtwoID = L2.ID \\\n",
    "                    WHERE ngram_size = ? AND L1.type_lc = ? AND L2.type_lc = ?\", \\\n",
    "                            (ngram_size, ngram[0], ngram[1]))  \n",
    "        elif ngram_size == 3:\n",
    "            coca_c.execute(\"SELECT freq FROM ngrams \\\n",
    "                    JOIN lexicon AS L1 ON ngrams.wordoneID = L1.ID \\\n",
    "                    JOIN lexicon AS L2 ON ngrams.wordtwoID = L2.ID \\\n",
    "                    JOIN lexicon AS L3 ON ngrams.wordthreeID = L3.ID \\\n",
    "                    WHERE ngram_size = ? AND L1.type_lc = ? AND L2.type_lc = ? AND L3.type_lc = ?\", \\\n",
    "                            (ngram_size, ngram[0], ngram[1], ngram[2]))\n",
    "        elif ngram_size == 4:\n",
    "            coca_c.execute(\"SELECT freq FROM ngrams \\\n",
    "                    JOIN lexicon AS L1 ON ngrams.wordoneID = L1.ID \\\n",
    "                    JOIN lexicon AS L2 ON ngrams.wordtwoID = L2.ID \\\n",
    "                    JOIN lexicon AS L3 ON ngrams.wordthreeID = L3.ID \\\n",
    "                    JOIN lexicon AS L4 ON ngrams.wordfourID = L4.ID \\\n",
    "                    WHERE ngram_size = ? AND L1.type_lc = ? AND L2.type_lc = ? AND L3.type_lc = ? AND L4.type_lc = ?\", \\\n",
    "                            (ngram_size, ngram[0], ngram[1], ngram[2], ngram[3]))\n",
    "        elif ngram_size == 5:\n",
    "            coca_c.execute(\"SELECT freq FROM ngrams \\\n",
    "                    JOIN lexicon AS L1 ON ngrams.wordoneID = L1.ID \\\n",
    "                    JOIN lexicon AS L2 ON ngrams.wordtwoID = L2.ID \\\n",
    "                    JOIN lexicon AS L3 ON ngrams.wordthreeID = L3.ID \\\n",
    "                    JOIN lexicon AS L4 ON ngrams.wordfourID = L4.ID \\\n",
    "                    JOIN lexicon AS L5 ON ngrams.wordfiveID = L5.ID \\\n",
    "                    WHERE ngram_size = ? AND L1.type_lc = ? AND L2.type_lc = ? AND L3.type_lc = ? AND L4.type_lc = ? AND L5.type_lc = ?\", \\\n",
    "                            (ngram_size, ngram[0], ngram[1], ngram[2], ngram[3], ngram[4]))\n",
    "        try:\n",
    "            freq = coca_c.fetchone()[0]\n",
    "        except:\n",
    "            freq = 0.0000000000000001    # 15 zeros after the decimal point\n",
    "        genre_counts[genre] = freq                \n",
    "        genre_counts[\"total\"] += freq \n",
    "        coca_conn.close()\n",
    "    return genre_counts\n",
    "\n",
    "#########################################\n",
    "\n",
    "erf_levels = ((1,\"one\"),(2,\"two\"),(3,\"three\"),(4,\"four\"),(5,\"five\"),(6,\"six\"))\n",
    "# 2-grams in GRC total\n",
    "output_headings = \"fic_tot, erf_level, ngram, freq_GRC, tokens_GRC, normFreq_GRC, freq_COCA, tokens_COCA, normFreq_COCA, keyness(LL), %DIFF\\n\"\n",
    "output_file = 'Output\\\\RQ6_grc_2gram_level_lists.csv'\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(output_headings)\n",
    "    for num,text in erf_levels:\n",
    "        num_str = str(num)\n",
    "        column = \"erf_\" + text + \"_freq\"\n",
    "        grc_c.execute(\"SELECT COUNT(*) FROM corpus WHERE erf_level = ?\", (num,))\n",
    "        tokens_GRC = grc_c.fetchone()[0]\n",
    "        min_freq = 20 * (tokens_GRC/1000000)\n",
    "        query = \"SELECT L1.type_lc || '_' || L2.type_lc AS ngram, {} AS freq \\\n",
    "                FROM ngrams \\\n",
    "                JOIN lexicon AS L1 ON ngrams.wordoneID = L1.ID \\\n",
    "                JOIN lexicon AS L2 ON ngrams.wordtwoID = L2.ID \\\n",
    "                WHERE ngram_size = 2 AND freq >= ? \\\n",
    "                ORDER BY freq DESC\".format(column)\n",
    "        grc_c.execute(query, (min_freq,))\n",
    "        print(\"Number of 2-grams in GRC total ERF Level\", num, \":\", len(grc_c.fetchall()))\n",
    "        grc_c.execute(query, (min_freq,))\n",
    "        list = grc_c.fetchall()\n",
    "        for row in list:\n",
    "            genre_counts = get_coca_info(row[0], 2)\n",
    "            normFreq_GRC = row[1] * (1000000/tokens_GRC)\n",
    "            tokens_COCA = 1139472212\n",
    "            freq_COCA = genre_counts[\"total\"]\n",
    "            normFreq_COCA = freq_COCA * (1000000/tokens_COCA)\n",
    "            expected_GRC_freq = (tokens_GRC * (row[1] + freq_COCA))/(tokens_GRC + tokens_COCA)\n",
    "            expected_COCA_freq = (tokens_COCA * (row[1] + freq_COCA))/(tokens_GRC + tokens_COCA) \n",
    "            keyness = 2 * ((row[1]*math.log(row[1]/expected_GRC_freq)) + (freq_COCA*math.log(freq_COCA/expected_COCA_freq)))\n",
    "            percent_diff = ((normFreq_GRC - normFreq_COCA)/normFreq_COCA) * 100\n",
    "            f.write('TOTAL' + ',' + str(num_str) + ',' + ','.join([str(x) for x in row]) + ',' + str(tokens_GRC) + ',' + str(normFreq_GRC) + \\\n",
    "        ',' + str(freq_COCA) + ',' + str(tokens_COCA) + ',' + str(normFreq_COCA) + ',' + str(keyness) + ',' + str(percent_diff) + '\\n')\n",
    "\n",
    "\n",
    "        # 2-grams in GRC fiction\n",
    "        grc_c.execute(\"SELECT COUNT(*) FROM corpus WHERE erf_level = ? AND f_nf = 'F'\", (num,))\n",
    "        tokens_GRC = grc_c.fetchone()[0]\n",
    "        min_freq = 20 * (tokens_GRC/1000000)\n",
    "        column = \"erf_\" + text + \"_fic_freq\"\n",
    "        query = \"SELECT L1.type_lc || '_' || L2.type_lc AS ngram, {} AS freq \\\n",
    "                FROM ngrams \\\n",
    "                JOIN lexicon AS L1 ON ngrams.wordoneID = L1.ID \\\n",
    "                JOIN lexicon AS L2 ON ngrams.wordtwoID = L2.ID \\\n",
    "                WHERE ngram_size = 2 AND freq >= ? \\\n",
    "                ORDER BY freq DESC\".format(column)\n",
    "        grc_c.execute(query, (min_freq,))\n",
    "        print(\"Number of 2-grams in GRC fiction ERF Level\", num, \":\", len(grc_c.fetchall()))\n",
    "        grc_c.execute(query, (min_freq,))\n",
    "        for row in grc_c.fetchall():\n",
    "            genre_counts = get_coca_info(row[0], 2)\n",
    "            normFreq_GRC = row[1] * (1000000/tokens_GRC)\n",
    "            tokens_COCA = 136217798\n",
    "            freq_COCA = genre_counts[\"fic\"]\n",
    "            normFreq_COCA = freq_COCA * (1000000/tokens_COCA)\n",
    "            expected_GRC_freq = (tokens_GRC * (row[1] + freq_COCA))/(tokens_GRC + tokens_COCA)\n",
    "            expected_COCA_freq = (tokens_COCA * (row[1] + freq_COCA))/(tokens_GRC + tokens_COCA) \n",
    "            keyness = 2 * ((row[1]*math.log(row[1]/expected_GRC_freq)) + (freq_COCA*math.log(freq_COCA/expected_COCA_freq)))\n",
    "            percent_diff = ((normFreq_GRC - normFreq_COCA)/normFreq_COCA) * 100\n",
    "            f.write('FIC' + ',' + str(num_str) + ',' + ','.join([str(x) for x in row]) + ',' + str(tokens_GRC) + ',' + str(normFreq_GRC) + \\\n",
    "        ',' + str(freq_COCA) + ',' + str(tokens_COCA) + ',' + str(normFreq_COCA) + ',' + str(keyness) + ',' + str(percent_diff) + '\\n')\n",
    "\n",
    "# 3-grams in GRC total\n",
    "output_file = 'Output\\\\RQ6_grc_3gram_level_lists.csv'\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(output_headings)\n",
    "    for num,text in erf_levels:\n",
    "        num_str = str(num)\n",
    "        column = \"erf_\" + text + \"_freq\"\n",
    "        grc_c.execute(\"SELECT COUNT(*) FROM corpus WHERE erf_level = ?\", (num,))\n",
    "        tokens_GRC = grc_c.fetchone()[0]\n",
    "        min_freq = 20 * (tokens_GRC/1000000)\n",
    "        query = \"SELECT L1.type_lc || '_' || L2.type_lc || '_' || L3.type_lc AS ngram, {} AS freq \\\n",
    "                FROM ngrams \\\n",
    "                JOIN lexicon AS L1 ON ngrams.wordoneID = L1.ID \\\n",
    "                JOIN lexicon AS L2 ON ngrams.wordtwoID = L2.ID \\\n",
    "                JOIN lexicon AS L3 ON ngrams.wordthreeID = L3.ID \\\n",
    "                WHERE ngram_size = 3 AND freq >= ? \\\n",
    "                ORDER BY freq DESC\".format(column)\n",
    "        grc_c.execute(query, (min_freq,))\n",
    "        print(\"Number of 3-grams in GRC total ERF Level\", num, \":\", len(grc_c.fetchall()))\n",
    "        grc_c.execute(query, (min_freq,))\n",
    "        list = grc_c.fetchall()\n",
    "        for row in list:\n",
    "            genre_counts = get_coca_info(row[0], 2)\n",
    "            normFreq_GRC = row[1] * (1000000/tokens_GRC)\n",
    "            tokens_COCA = 1139472212\n",
    "            freq_COCA = genre_counts[\"total\"]\n",
    "            normFreq_COCA = freq_COCA * (1000000/tokens_COCA)\n",
    "            expected_GRC_freq = (tokens_GRC * (row[1] + freq_COCA))/(tokens_GRC + tokens_COCA)\n",
    "            expected_COCA_freq = (tokens_COCA * (row[1] + freq_COCA))/(tokens_GRC + tokens_COCA) \n",
    "            keyness = 2 * ((row[1]*math.log(row[1]/expected_GRC_freq)) + (freq_COCA*math.log(freq_COCA/expected_COCA_freq)))\n",
    "            percent_diff = ((normFreq_GRC - normFreq_COCA)/normFreq_COCA) * 100\n",
    "            f.write('TOTAL' + ',' + str(num_str) + ',' + ','.join([str(x) for x in row]) + ',' + str(tokens_GRC) + ',' + str(normFreq_GRC) + \\\n",
    "        ',' + str(freq_COCA) + ',' + str(tokens_COCA) + ',' + str(normFreq_COCA) + ',' + str(keyness) + ',' + str(percent_diff) + '\\n')\n",
    "\n",
    "\n",
    "        # 3-grams in GRC fiction\n",
    "        grc_c.execute(\"SELECT COUNT(*) FROM corpus WHERE erf_level = ? AND f_nf = 'F'\", (num,))\n",
    "        tokens_GRC = grc_c.fetchone()[0]\n",
    "        min_freq = 20 * (tokens_GRC/1000000)\n",
    "        column = \"erf_\" + text + \"_fic_freq\"\n",
    "        query = \"SELECT L1.type_lc || '_' || L2.type_lc || '_' || L3.type_lc AS ngram, {} AS freq \\\n",
    "                FROM ngrams \\\n",
    "                JOIN lexicon AS L1 ON ngrams.wordoneID = L1.ID \\\n",
    "                JOIN lexicon AS L2 ON ngrams.wordtwoID = L2.ID \\\n",
    "                JOIN lexicon AS L3 ON ngrams.wordthreeID = L3.ID \\\n",
    "                WHERE ngram_size = 3 AND freq >= ? \\\n",
    "                ORDER BY freq DESC\".format(column)\n",
    "        grc_c.execute(query, (min_freq,))\n",
    "        print(\"Number of 3-grams in GRC fiction ERF Level\", num, \":\", len(grc_c.fetchall()))\n",
    "        grc_c.execute(query, (min_freq,))\n",
    "        for row in grc_c.fetchall():\n",
    "            genre_counts = get_coca_info(row[0], 2)\n",
    "            normFreq_GRC = row[1] * (1000000/tokens_GRC)\n",
    "            tokens_COCA = 136217798\n",
    "            freq_COCA = genre_counts[\"fic\"]\n",
    "            normFreq_COCA = freq_COCA * (1000000/tokens_COCA)\n",
    "            expected_GRC_freq = (tokens_GRC * (row[1] + freq_COCA))/(tokens_GRC + tokens_COCA)\n",
    "            expected_COCA_freq = (tokens_COCA * (row[1] + freq_COCA))/(tokens_GRC + tokens_COCA) \n",
    "            keyness = 2 * ((row[1]*math.log(row[1]/expected_GRC_freq)) + (freq_COCA*math.log(freq_COCA/expected_COCA_freq)))\n",
    "            percent_diff = ((normFreq_GRC - normFreq_COCA)/normFreq_COCA) * 100\n",
    "            f.write('FIC' + ',' + str(num_str) + ',' + ','.join([str(x) for x in row]) + ',' + str(tokens_GRC) + ',' + str(normFreq_GRC) + \\\n",
    "        ',' + str(freq_COCA) + ',' + str(tokens_COCA) + ',' + str(normFreq_COCA) + ',' + str(keyness) + ',' + str(percent_diff) + '\\n')\n",
    "\n",
    "\n",
    "\n",
    "# 4-grams in GRC total\n",
    "output_file = 'Output\\\\RQ6_grc_4gram_level_lists.csv'\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(output_headings)\n",
    "    for num,text in erf_levels:\n",
    "        num_str = str(num)\n",
    "        column = \"erf_\" + text + \"_freq\"\n",
    "        grc_c.execute(\"SELECT COUNT(*) FROM corpus WHERE erf_level = ?\", (num,))\n",
    "        tokens_GRC = grc_c.fetchone()[0]\n",
    "        min_freq = 20 * (tokens_GRC/1000000)\n",
    "        query = \"SELECT L1.type_lc || '_' || L2.type_lc || '_' || L3.type_lc || '_' || L4.type_lc AS ngram, {} AS freq \\\n",
    "                FROM ngrams \\\n",
    "                JOIN lexicon AS L1 ON ngrams.wordoneID = L1.ID \\\n",
    "                JOIN lexicon AS L2 ON ngrams.wordtwoID = L2.ID \\\n",
    "                JOIN lexicon AS L3 ON ngrams.wordthreeID = L3.ID \\\n",
    "                JOIN lexicon AS L4 ON ngrams.wordfourID = L4.ID \\\n",
    "                WHERE ngram_size = 4 AND freq >= ? \\\n",
    "                ORDER BY freq DESC\".format(column)\n",
    "        grc_c.execute(query, (min_freq,))\n",
    "        print(\"Number of 4-grams in GRC total ERF Level\", num, \":\", len(grc_c.fetchall()))\n",
    "        grc_c.execute(query, (min_freq,))\n",
    "        list = grc_c.fetchall()\n",
    "        for row in list:\n",
    "            genre_counts = get_coca_info(row[0], 2)\n",
    "            normFreq_GRC = row[1] * (1000000/tokens_GRC)\n",
    "            tokens_COCA = 1139472212\n",
    "            freq_COCA = genre_counts[\"total\"]\n",
    "            normFreq_COCA = freq_COCA * (1000000/tokens_COCA)\n",
    "            expected_GRC_freq = (tokens_GRC * (row[1] + freq_COCA))/(tokens_GRC + tokens_COCA)\n",
    "            expected_COCA_freq = (tokens_COCA * (row[1] + freq_COCA))/(tokens_GRC + tokens_COCA) \n",
    "            keyness = 2 * ((row[1]*math.log(row[1]/expected_GRC_freq)) + (freq_COCA*math.log(freq_COCA/expected_COCA_freq)))\n",
    "            percent_diff = ((normFreq_GRC - normFreq_COCA)/normFreq_COCA) * 100\n",
    "            f.write('TOTAL' + ',' + str(num_str) + ',' + ','.join([str(x) for x in row]) + ',' + str(tokens_GRC) + ',' + str(normFreq_GRC) + \\\n",
    "        ',' + str(freq_COCA) + ',' + str(tokens_COCA) + ',' + str(normFreq_COCA) + ',' + str(keyness) + ',' + str(percent_diff) + '\\n')\n",
    "\n",
    "\n",
    "        # 4-grams in GRC fiction\n",
    "        grc_c.execute(\"SELECT COUNT(*) FROM corpus WHERE erf_level = ? AND f_nf = 'F'\", (num,))\n",
    "        tokens_GRC = grc_c.fetchone()[0]\n",
    "        min_freq = 20 * (tokens_GRC/1000000)\n",
    "        column = \"erf_\" + text + \"_fic_freq\"\n",
    "        query = \"SELECT L1.type_lc || '_' || L2.type_lc || '_' || L3.type_lc || '_' || L4.type_lc AS ngram, {} AS freq \\\n",
    "                FROM ngrams \\\n",
    "                JOIN lexicon AS L1 ON ngrams.wordoneID = L1.ID \\\n",
    "                JOIN lexicon AS L2 ON ngrams.wordtwoID = L2.ID \\\n",
    "                JOIN lexicon AS L3 ON ngrams.wordthreeID = L3.ID \\\n",
    "                JOIN lexicon AS L4 ON ngrams.wordfourID = L4.ID \\\n",
    "                WHERE ngram_size = 4 AND freq >= ? \\\n",
    "                ORDER BY freq DESC\".format(column)\n",
    "        grc_c.execute(query, (min_freq,))\n",
    "        print(\"Number of 4-grams in GRC fiction ERF Level\", num, \":\", len(grc_c.fetchall()))\n",
    "        grc_c.execute(query, (min_freq,))\n",
    "        for row in grc_c.fetchall():\n",
    "            genre_counts = get_coca_info(row[0], 2)\n",
    "            normFreq_GRC = row[1] * (1000000/tokens_GRC)\n",
    "            tokens_COCA = 136217798\n",
    "            freq_COCA = genre_counts[\"fic\"]\n",
    "            normFreq_COCA = freq_COCA * (1000000/tokens_COCA)\n",
    "            expected_GRC_freq = (tokens_GRC * (row[1] + freq_COCA))/(tokens_GRC + tokens_COCA)\n",
    "            expected_COCA_freq = (tokens_COCA * (row[1] + freq_COCA))/(tokens_GRC + tokens_COCA) \n",
    "            keyness = 2 * ((row[1]*math.log(row[1]/expected_GRC_freq)) + (freq_COCA*math.log(freq_COCA/expected_COCA_freq)))\n",
    "            percent_diff = ((normFreq_GRC - normFreq_COCA)/normFreq_COCA) * 100\n",
    "            f.write('FIC' + ',' + str(num_str) + ',' + ','.join([str(x) for x in row]) + ',' + str(tokens_GRC) + ',' + str(normFreq_GRC) + \\\n",
    "        ',' + str(freq_COCA) + ',' + str(tokens_COCA) + ',' + str(normFreq_COCA) + ',' + str(keyness) + ',' + str(percent_diff) + '\\n')\n",
    "\n",
    "# 5-grams in GRC total\n",
    "output_file = 'Output\\\\RQ6_grc_5gram_level_lists.csv'\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(output_headings)\n",
    "    for num,text in erf_levels:\n",
    "        num_str = str(num)\n",
    "        column = \"erf_\" + text + \"_freq\"\n",
    "        grc_c.execute(\"SELECT COUNT(*) FROM corpus WHERE erf_level = ?\", (num,))\n",
    "        tokens_GRC = grc_c.fetchone()[0]\n",
    "        min_freq = 20 * (tokens_GRC/1000000)\n",
    "        query = \"SELECT L1.type_lc || '_' || L2.type_lc || '_' || L3.type_lc || '_' || L4.type_lc || '_' || L5.type_lc AS ngram, {} AS freq \\\n",
    "                FROM ngrams \\\n",
    "                JOIN lexicon AS L1 ON ngrams.wordoneID = L1.ID \\\n",
    "                JOIN lexicon AS L2 ON ngrams.wordtwoID = L2.ID \\\n",
    "                JOIN lexicon AS L3 ON ngrams.wordthreeID = L3.ID \\\n",
    "                JOIN lexicon AS L4 ON ngrams.wordfourID = L4.ID \\\n",
    "                JOIN lexicon AS L5 ON ngrams.wordfiveID = L5.ID \\\n",
    "                WHERE ngram_size = 5 AND freq >= ? \\\n",
    "                ORDER BY freq DESC\".format(column)\n",
    "        grc_c.execute(query, (min_freq,))\n",
    "        print(\"Number of 5-grams in GRC total ERF Level\", num, \":\", len(grc_c.fetchall()))\n",
    "        grc_c.execute(query, (min_freq,))\n",
    "        list = grc_c.fetchall()\n",
    "        for row in list:\n",
    "            genre_counts = get_coca_info(row[0], 2)\n",
    "            normFreq_GRC = row[1] * (1000000/tokens_GRC)\n",
    "            tokens_COCA = 1139472212\n",
    "            freq_COCA = genre_counts[\"total\"]\n",
    "            normFreq_COCA = freq_COCA * (1000000/tokens_COCA)\n",
    "            expected_GRC_freq = (tokens_GRC * (row[1] + freq_COCA))/(tokens_GRC + tokens_COCA)\n",
    "            expected_COCA_freq = (tokens_COCA * (row[1] + freq_COCA))/(tokens_GRC + tokens_COCA) \n",
    "            keyness = 2 * ((row[1]*math.log(row[1]/expected_GRC_freq)) + (freq_COCA*math.log(freq_COCA/expected_COCA_freq)))\n",
    "            percent_diff = ((normFreq_GRC - normFreq_COCA)/normFreq_COCA) * 100\n",
    "            f.write('TOTAL' + ',' + str(num_str) + ',' + ','.join([str(x) for x in row]) + ',' + str(tokens_GRC) + ',' + str(normFreq_GRC) + \\\n",
    "        ',' + str(freq_COCA) + ',' + str(tokens_COCA) + ',' + str(normFreq_COCA) + ',' + str(keyness) + ',' + str(percent_diff) + '\\n')\n",
    "\n",
    "\n",
    "        # 5-grams in GRC fiction\n",
    "        grc_c.execute(\"SELECT COUNT(*) FROM corpus WHERE erf_level = ? AND f_nf = 'F'\", (num,))\n",
    "        tokens_GRC = grc_c.fetchone()[0]\n",
    "        min_freq = 20 * (tokens_GRC/1000000)\n",
    "        column = \"erf_\" + text + \"_fic_freq\"\n",
    "        query = \"SELECT L1.type_lc || '_' || L2.type_lc || '_' || L3.type_lc || '_' || L4.type_lc || '_' || L5.type_lc AS ngram, {} AS freq \\\n",
    "                FROM ngrams \\\n",
    "                JOIN lexicon AS L1 ON ngrams.wordoneID = L1.ID \\\n",
    "                JOIN lexicon AS L2 ON ngrams.wordtwoID = L2.ID \\\n",
    "                JOIN lexicon AS L3 ON ngrams.wordthreeID = L3.ID \\\n",
    "                JOIN lexicon AS L4 ON ngrams.wordfourID = L4.ID \\\n",
    "                JOIN lexicon AS L5 ON ngrams.wordfiveID = L5.ID \\\n",
    "                WHERE ngram_size = 5 AND freq >= ? \\\n",
    "                ORDER BY freq DESC\".format(column)\n",
    "        grc_c.execute(query, (min_freq,))\n",
    "        print(\"Number of 5-grams in GRC fiction ERF Level\", num, \":\", len(grc_c.fetchall()))\n",
    "        grc_c.execute(query, (min_freq,))\n",
    "        for row in grc_c.fetchall():\n",
    "            genre_counts = get_coca_info(row[0], 2)\n",
    "            normFreq_GRC = row[1] * (1000000/tokens_GRC)\n",
    "            tokens_COCA = 136217798\n",
    "            freq_COCA = genre_counts[\"fic\"]\n",
    "            normFreq_COCA = freq_COCA * (1000000/tokens_COCA)\n",
    "            expected_GRC_freq = (tokens_GRC * (row[1] + freq_COCA))/(tokens_GRC + tokens_COCA)\n",
    "            expected_COCA_freq = (tokens_COCA * (row[1] + freq_COCA))/(tokens_GRC + tokens_COCA) \n",
    "            keyness = 2 * ((row[1]*math.log(row[1]/expected_GRC_freq)) + (freq_COCA*math.log(freq_COCA/expected_COCA_freq)))\n",
    "            percent_diff = ((normFreq_GRC - normFreq_COCA)/normFreq_COCA) * 100\n",
    "            f.write('FIC' + ',' + str(num_str) + ',' + ','.join([str(x) for x in row]) + ',' + str(tokens_GRC) + ',' + str(normFreq_GRC) + \\\n",
    "        ',' + str(freq_COCA) + ',' + str(tokens_COCA) + ',' + str(normFreq_COCA) + ',' + str(keyness) + ',' + str(percent_diff) + '\\n')\n",
    "\n",
    "\n",
    "grc_conn.commit()\n",
    "grc_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# COCA 2grams - fiction\n",
    "\n",
    "coca_filename = 'D:\\\\coca_fic.sqlite'\n",
    "coca_conn = sqlite3.connect(coca_filename)\n",
    "coca_c = coca_conn.cursor()\n",
    "\n",
    "output_headings = \"word1, word2, freq\\n\"\n",
    "output_file = 'Output\\\\RQ6_coca_fic_2gram.csv'\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(output_headings)\n",
    "\n",
    "    coca_c.execute(\"SELECT ID FROM lexicon WHERE type_lc = '@@@@@@@@@@'\")\n",
    "    typeID = coca_c.fetchone()[0]\n",
    "    coca_c.execute(\"SELECT COUNT(*) FROM corpus WHERE word_typeID != ?\", (typeID,))\n",
    "    total_tokens = coca_c.fetchone()[0]\n",
    "    min_freq = 20 * (total_tokens / 1000000)\n",
    "    coca_c.execute(\"SELECT L1.type_lc AS wordone, L2.type_lc AS wordtwo, freq \\\n",
    "                FROM ngrams \\\n",
    "                JOIN lexicon AS L1 ON ngrams.wordoneID = L1.ID \\\n",
    "                JOIN lexicon AS L2 ON ngrams.wordtwoID = L2.ID \\\n",
    "                WHERE ngram_size = 2 AND freq >= ? \\\n",
    "                AND wordoneID != ? AND wordtwoID != ? \\\n",
    "                ORDER BY freq DESC\", (min_freq,typeID,typeID))\n",
    "    \n",
    "    for row in coca_c.fetchall():\n",
    "        f.write(','.join([str(x) for x in row]) + '\\n')\n",
    "    \n",
    "    \n",
    "    coca_conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing genre: acad\n",
      "Processing genre: blog\n",
      "Processing genre: fic\n",
      "Processing genre: mag\n",
      "Processing genre: news\n",
      "Processing genre: spok\n",
      "Processing genre: tvm\n",
      "Processing genre: web\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# COCA 2grams-total\n",
    "import sqlite3\n",
    "\n",
    "# create dictionary of ngrams where key is ngram and value is frequency\n",
    "ngrams = {}\n",
    "genres = (\"acad\", \"blog\", \"fic\", \"mag\", \"news\", \"spok\", \"tvm\", \"web\")\n",
    "\n",
    "for genre in genres:\n",
    "    print(\"Processing genre:\", genre)\n",
    "    coca_filename = 'D:\\\\coca_' + genre + '.sqlite'\n",
    "    coca_conn = sqlite3.connect(coca_filename)\n",
    "    coca_c = coca_conn.cursor()\n",
    "    \n",
    "    coca_c.execute(\"CREATE INDEX IF NOT EXISTS ngram_count_IN ON ngrams (ngram_size, freq)\")\n",
    "    coca_conn.commit()\n",
    "\n",
    "    coca_c.execute(\"SELECT ID FROM lexicon WHERE type_lc = '@@@@@@@@@@'\")\n",
    "    typeID = coca_c.fetchone()[0]\n",
    "    coca_c.execute(\"SELECT COUNT(*) FROM corpus WHERE word_typeID != ?\", (typeID,))\n",
    "    total_tokens = coca_c.fetchone()[0]\n",
    "    min_freq = 5 * (total_tokens / 1000000)\n",
    "    \n",
    "    coca_c.execute(\"SELECT L1.type_lc || '_' || L2.type_lc AS word, freq \\\n",
    "                    FROM ngrams \\\n",
    "                    JOIN lexicon AS L1 ON ngrams.wordoneID = L1.ID \\\n",
    "                    JOIN lexicon AS L2 ON ngrams.wordtwoID = L2.ID \\\n",
    "                    WHERE ngram_size = 2 AND freq >= ? \\\n",
    "                    AND wordoneID != ? AND wordtwoID != ? \\\n",
    "                    ORDER BY freq DESC\", (min_freq, typeID, typeID))\n",
    "\n",
    "    for row in coca_c.fetchall():\n",
    "        # if ngram is already in dictionary, add the frequency to the existing value\n",
    "        if row[0] in ngrams:\n",
    "            ngrams[row[0]] += row[1]\n",
    "        # if ngram is not in dictionary, add it with the frequency as the value\n",
    "        else:\n",
    "            ngrams[row[0]] = row[1]\n",
    "\n",
    "    coca_conn.close()\n",
    "\n",
    "# arrange the dictionary in descending frequency order\n",
    "sorted_ngrams = sorted(ngrams.items(), key=lambda x: x[1], reverse=True)\n",
    "output_file = 'Output\\\\RQ6_coca_tot_2gram.csv'\n",
    "output_headings = \"ngram, freq\\n\"\n",
    "\n",
    "# write the dictionary to a csv file\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(output_headings)\n",
    "    for ngram in sorted_ngrams:\n",
    "        if ngram[1] >= 22789: # 20 per million based on COCA total count\n",
    "            f.write(str(ngram[0]) + ',' + str(ngram[1]) + '\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing genre: acad\n",
      "Processing genre: blog\n",
      "Processing genre: fic\n",
      "Processing genre: mag\n",
      "Processing genre: news\n",
      "Processing genre: spok\n",
      "Processing genre: tvm\n",
      "Processing genre: web\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# COCA 3 grams\n",
    "\n",
    "coca_filename = 'D:\\\\coca_fic.sqlite'\n",
    "coca_conn = sqlite3.connect(coca_filename)\n",
    "coca_c = coca_conn.cursor()\n",
    "\n",
    "output_headings = \"word1, word2, word3, freq\\n\"\n",
    "output_file = 'Output\\\\RQ6_coca_fic_3gram.csv'\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(output_headings)\n",
    "\n",
    "    coca_c.execute(\"SELECT ID FROM lexicon WHERE type_lc = '@@@@@@@@@@'\")\n",
    "    typeID = coca_c.fetchone()[0]\n",
    "    coca_c.execute(\"SELECT COUNT(*) FROM corpus WHERE word_typeID != ?\", (typeID,))\n",
    "    total_tokens = coca_c.fetchone()[0]\n",
    "    min_freq = 20 * (total_tokens / 1000000)\n",
    "    coca_c.execute(\"SELECT L1.type_lc AS wordone, L2.type_lc AS wordtwo, L3.type_lc AS wordthree, freq \\\n",
    "                FROM ngrams \\\n",
    "                JOIN lexicon AS L1 ON ngrams.wordoneID = L1.ID \\\n",
    "                JOIN lexicon AS L2 ON ngrams.wordtwoID = L2.ID \\\n",
    "                JOIN lexicon AS L3 ON ngrams.wordthreeID = L3.ID \\\n",
    "                WHERE ngram_size = 3 AND freq >= ? \\\n",
    "                AND wordoneID != ? AND wordtwoID != ? AND wordthreeID != ? \\\n",
    "                ORDER BY freq DESC\", (min_freq,typeID,typeID,typeID))\n",
    "    \n",
    "    for row in coca_c.fetchall():\n",
    "        f.write(','.join([str(x) for x in row]) + '\\n')\n",
    "    \n",
    "    \n",
    "    coca_conn.close()\n",
    "\n",
    "\n",
    "# create dictionary of ngrams where key is ngram and value is frequency\n",
    "ngrams = {}\n",
    "genres = (\"acad\", \"blog\", \"fic\", \"mag\", \"news\", \"spok\", \"tvm\", \"web\")\n",
    "\n",
    "for genre in genres:\n",
    "    print(\"Processing genre:\", genre)\n",
    "    coca_filename = 'D:\\\\coca_' + genre + '.sqlite'\n",
    "    coca_conn = sqlite3.connect(coca_filename)\n",
    "    coca_c = coca_conn.cursor()\n",
    "    \n",
    "    coca_c.execute(\"CREATE INDEX IF NOT EXISTS ngram_count_IN ON ngrams (ngram_size, freq)\")\n",
    "    coca_conn.commit()\n",
    "\n",
    "    coca_c.execute(\"SELECT ID FROM lexicon WHERE type_lc = '@@@@@@@@@@'\")\n",
    "    typeID = coca_c.fetchone()[0]\n",
    "    coca_c.execute(\"SELECT COUNT(*) FROM corpus WHERE word_typeID != ?\", (typeID,))\n",
    "    total_tokens = coca_c.fetchone()[0]\n",
    "    min_freq = 5 * (total_tokens / 1000000)\n",
    "    \n",
    "    coca_c.execute(\"SELECT L1.type_lc || '_' || L2.type_lc || '_' || L3.type_lc AS word, freq \\\n",
    "                    FROM ngrams \\\n",
    "                    JOIN lexicon AS L1 ON ngrams.wordoneID = L1.ID \\\n",
    "                    JOIN lexicon AS L2 ON ngrams.wordtwoID = L2.ID \\\n",
    "                    JOIN lexicon AS L3 ON ngrams.wordthreeID = L3.ID \\\n",
    "                    WHERE ngram_size = 3 AND freq >= ? \\\n",
    "                    AND wordoneID != ? AND wordtwoID != ? AND wordthreeID != ? \\\n",
    "                    ORDER BY freq DESC\", (min_freq, typeID, typeID, typeID))\n",
    "\n",
    "\n",
    "    for row in coca_c.fetchall():\n",
    "        # if ngram is already in dictionary, add the frequency to the existing value\n",
    "        if row[0] in ngrams:\n",
    "            ngrams[row[0]] += row[1]\n",
    "        # if ngram is not in dictionary, add it with the frequency as the value\n",
    "        else:\n",
    "            ngrams[row[0]] = row[1]\n",
    "\n",
    "    coca_conn.close()\n",
    "\n",
    "# arrange the dictionary in descending frequency order\n",
    "sorted_ngrams = sorted(ngrams.items(), key=lambda x: x[1], reverse=True)\n",
    "output_file = 'Output\\\\RQ6_coca_tot_3gram.csv'\n",
    "output_headings = \"ngram, freq\\n\"\n",
    "\n",
    "# write the dictionary to a csv file\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(output_headings)\n",
    "    for ngram in sorted_ngrams:\n",
    "        if ngram[1] >= 22789: # 20 per million based on COCA total count\n",
    "            f.write(str(ngram[0]) + ',' + str(ngram[1]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing genre: acad\n",
      "Processing genre: blog\n",
      "Processing genre: fic\n",
      "Processing genre: mag\n",
      "Processing genre: news\n",
      "Processing genre: spok\n",
      "Processing genre: tvm\n",
      "Processing genre: web\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# COCA 4 grams\n",
    "\n",
    "coca_filename = 'D:\\\\coca_fic.sqlite'\n",
    "coca_conn = sqlite3.connect(coca_filename)\n",
    "coca_c = coca_conn.cursor()\n",
    "\n",
    "output_headings = \"word1, word2, word3, word4, freq\\n\"\n",
    "output_file = 'Output\\\\RQ6_coca_fic_4gram.csv'\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(output_headings)\n",
    "\n",
    "    coca_c.execute(\"SELECT ID FROM lexicon WHERE type_lc = '@@@@@@@@@@'\")\n",
    "    typeID = coca_c.fetchone()[0]\n",
    "    coca_c.execute(\"SELECT COUNT(*) FROM corpus WHERE word_typeID != ?\", (typeID,))\n",
    "    total_tokens = coca_c.fetchone()[0]\n",
    "    min_freq = 20 * (total_tokens / 1000000)\n",
    "    coca_c.execute(\"SELECT L1.type_lc AS wordone, L2.type_lc AS wordtwo, L3.type_lc AS wordthree, \\\n",
    "                   L4.type_lc AS wordfour, freq \\\n",
    "                FROM ngrams \\\n",
    "                JOIN lexicon AS L1 ON ngrams.wordoneID = L1.ID \\\n",
    "                JOIN lexicon AS L2 ON ngrams.wordtwoID = L2.ID \\\n",
    "                JOIN lexicon AS L3 ON ngrams.wordthreeID = L3.ID \\\n",
    "                JOIN lexicon AS L4 ON ngrams.wordfourID = L4.ID \\\n",
    "                WHERE ngram_size = 4 AND freq >= ? \\\n",
    "                AND wordoneID != ? AND wordtwoID != ? AND wordthreeID != ? AND wordfourID != ? \\\n",
    "                ORDER BY freq DESC\", (min_freq,typeID,typeID,typeID,typeID))\n",
    "    \n",
    "    for row in coca_c.fetchall():\n",
    "        f.write(','.join([str(x) for x in row]) + '\\n')\n",
    "    \n",
    "    \n",
    "    coca_conn.close()\n",
    "\n",
    "\n",
    "# create dictionary of ngrams where key is ngram and value is frequency\n",
    "ngrams = {}\n",
    "genres = (\"acad\", \"blog\", \"fic\", \"mag\", \"news\", \"spok\", \"tvm\", \"web\")\n",
    "\n",
    "for genre in genres:\n",
    "    print(\"Processing genre:\", genre)\n",
    "    coca_filename = 'D:\\\\coca_' + genre + '.sqlite'\n",
    "    coca_conn = sqlite3.connect(coca_filename)\n",
    "    coca_c = coca_conn.cursor()\n",
    "    \n",
    "    coca_c.execute(\"CREATE INDEX IF NOT EXISTS ngram_count_IN ON ngrams (ngram_size, freq)\")\n",
    "    coca_conn.commit()\n",
    "\n",
    "    coca_c.execute(\"SELECT ID FROM lexicon WHERE type_lc = '@@@@@@@@@@'\")\n",
    "    typeID = coca_c.fetchone()[0]\n",
    "    coca_c.execute(\"SELECT COUNT(*) FROM corpus WHERE word_typeID != ?\", (typeID,))\n",
    "    total_tokens = coca_c.fetchone()[0]\n",
    "    min_freq = 5 * (total_tokens / 1000000)\n",
    "    \n",
    "    coca_c.execute(\"SELECT L1.type_lc || '_' || L2.type_lc || '_' || L3.type_lc || '_' || L4.type_lc AS word, freq \\\n",
    "                    FROM ngrams \\\n",
    "                    JOIN lexicon AS L1 ON ngrams.wordoneID = L1.ID \\\n",
    "                    JOIN lexicon AS L2 ON ngrams.wordtwoID = L2.ID \\\n",
    "                    JOIN lexicon AS L3 ON ngrams.wordthreeID = L3.ID \\\n",
    "                    JOIN lexicon AS L4 ON ngrams.wordfourID = L4.ID \\\n",
    "                    WHERE ngram_size = 4 AND freq >= ? \\\n",
    "                    AND wordoneID != ? AND wordtwoID != ? AND wordthreeID != ? AND wordfourID != ? \\\n",
    "                    ORDER BY freq DESC\", (min_freq, typeID, typeID, typeID, typeID))\n",
    "\n",
    "\n",
    "    for row in coca_c.fetchall():\n",
    "        # if ngram is already in dictionary, add the frequency to the existing value\n",
    "        if row[0] in ngrams:\n",
    "            ngrams[row[0]] += row[1]\n",
    "        # if ngram is not in dictionary, add it with the frequency as the value\n",
    "        else:\n",
    "            ngrams[row[0]] = row[1]\n",
    "\n",
    "    coca_conn.close()\n",
    "\n",
    "# arrange the dictionary in descending frequency order\n",
    "sorted_ngrams = sorted(ngrams.items(), key=lambda x: x[1], reverse=True)\n",
    "output_file = 'Output\\\\RQ6_coca_tot_4gram.csv'\n",
    "output_headings = \"ngram, freq\\n\"\n",
    "\n",
    "# write the dictionary to a csv file\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(output_headings)\n",
    "    for ngram in sorted_ngrams:\n",
    "        if ngram[1] >= 22789: # 20 per million based on COCA total count\n",
    "            f.write(str(ngram[0]) + ',' + str(ngram[1]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing genre: acad\n",
      "Processing genre: blog\n",
      "Processing genre: fic\n",
      "Processing genre: mag\n",
      "Processing genre: news\n",
      "Processing genre: spok\n",
      "Processing genre: tvm\n",
      "Processing genre: web\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# COCA 5 grams\n",
    "\n",
    "coca_filename = 'D:\\\\coca_fic.sqlite'\n",
    "coca_conn = sqlite3.connect(coca_filename)\n",
    "coca_c = coca_conn.cursor()\n",
    "\n",
    "output_headings = \"word1, word2, word3, word4, word5, freq\\n\"\n",
    "output_file = 'Output\\\\RQ6_coca_fic_5gram.csv'\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(output_headings)\n",
    "\n",
    "    coca_c.execute(\"SELECT ID FROM lexicon WHERE type_lc = '@@@@@@@@@@'\")\n",
    "    typeID = coca_c.fetchone()[0]\n",
    "    coca_c.execute(\"SELECT COUNT(*) FROM corpus WHERE word_typeID != ?\", (typeID,))\n",
    "    total_tokens = coca_c.fetchone()[0]\n",
    "    min_freq = 20 * (total_tokens / 1000000)\n",
    "    coca_c.execute(\"SELECT L1.type_lc AS wordone, L2.type_lc AS wordtwo, L3.type_lc AS wordthree, \\\n",
    "                   L4.type_lc AS wordfour, L5.type_lc AS wordfive, freq \\\n",
    "                FROM ngrams \\\n",
    "                JOIN lexicon AS L1 ON ngrams.wordoneID = L1.ID \\\n",
    "                JOIN lexicon AS L2 ON ngrams.wordtwoID = L2.ID \\\n",
    "                JOIN lexicon AS L3 ON ngrams.wordthreeID = L3.ID \\\n",
    "                JOIN lexicon AS L4 ON ngrams.wordfourID = L4.ID \\\n",
    "                JOIN lexicon AS L5 ON ngrams.wordfiveID = L5.ID \\\n",
    "                WHERE ngram_size = 5 AND freq >= ? \\\n",
    "                AND wordoneID != ? AND wordtwoID != ? AND wordthreeID != ? AND wordfourID != ? AND wordfiveID != ? \\\n",
    "                ORDER BY freq DESC\", (min_freq,typeID,typeID,typeID,typeID,typeID))\n",
    "    \n",
    "    for row in coca_c.fetchall():\n",
    "        f.write(','.join([str(x) for x in row]) + '\\n')\n",
    "    \n",
    "    \n",
    "    coca_conn.close()\n",
    "\n",
    "\n",
    "# create dictionary of ngrams where key is ngram and value is frequency\n",
    "ngrams = {}\n",
    "genres = (\"acad\", \"blog\", \"fic\", \"mag\", \"news\", \"spok\", \"tvm\", \"web\")\n",
    "\n",
    "for genre in genres:\n",
    "    print(\"Processing genre:\", genre)\n",
    "    coca_filename = 'D:\\\\coca_' + genre + '.sqlite'\n",
    "    coca_conn = sqlite3.connect(coca_filename)\n",
    "    coca_c = coca_conn.cursor()\n",
    "    \n",
    "    coca_c.execute(\"CREATE INDEX IF NOT EXISTS ngram_count_IN ON ngrams (ngram_size, freq)\")\n",
    "    coca_conn.commit()\n",
    "\n",
    "    coca_c.execute(\"SELECT ID FROM lexicon WHERE type_lc = '@@@@@@@@@@'\")\n",
    "    typeID = coca_c.fetchone()[0]\n",
    "    coca_c.execute(\"SELECT COUNT(*) FROM corpus WHERE word_typeID != ?\", (typeID,))\n",
    "    total_tokens = coca_c.fetchone()[0]\n",
    "    min_freq = 5 * (total_tokens / 1000000)\n",
    "    \n",
    "    coca_c.execute(\"SELECT L1.type_lc || '_' || L2.type_lc || '_' || L3.type_lc || '_' || L4.type_lc || '_' || L5.type_lc AS word, freq \\\n",
    "                    FROM ngrams \\\n",
    "                    JOIN lexicon AS L1 ON ngrams.wordoneID = L1.ID \\\n",
    "                    JOIN lexicon AS L2 ON ngrams.wordtwoID = L2.ID \\\n",
    "                    JOIN lexicon AS L3 ON ngrams.wordthreeID = L3.ID \\\n",
    "                    JOIN lexicon AS L4 ON ngrams.wordfourID = L4.ID \\\n",
    "                    JOIN lexicon AS L5 ON ngrams.wordfiveID = L5.ID \\\n",
    "                    WHERE ngram_size = 5 AND freq >= ? \\\n",
    "                    AND wordoneID != ? AND wordtwoID != ? AND wordthreeID != ? AND wordfourID != ? AND wordfiveID != ? \\\n",
    "                    ORDER BY freq DESC\", (min_freq, typeID, typeID, typeID, typeID, typeID))\n",
    "\n",
    "\n",
    "    for row in coca_c.fetchall():\n",
    "        # if ngram is already in dictionary, add the frequency to the existing value\n",
    "        if row[0] in ngrams:\n",
    "            ngrams[row[0]] += row[1]\n",
    "        # if ngram is not in dictionary, add it with the frequency as the value\n",
    "        else:\n",
    "            ngrams[row[0]] = row[1]\n",
    "\n",
    "    coca_conn.close()\n",
    "\n",
    "# arrange the dictionary in descending frequency order\n",
    "sorted_ngrams = sorted(ngrams.items(), key=lambda x: x[1], reverse=True)\n",
    "output_file = 'Output\\\\RQ6_coca_tot_5gram.csv'\n",
    "output_headings = \"ngram, freq\\n\"\n",
    "\n",
    "# write the dictionary to a csv file\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(output_headings)\n",
    "    for ngram in sorted_ngrams:\n",
    "        if ngram[1] >= 22789: # 20 per million based on COCA total count\n",
    "            f.write(str(ngram[0]) + ',' + str(ngram[1]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating indices\n",
      "updating total_grc_freq\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "grc_conn = sqlite3.connect('D:\\\\graded_readers_mwe.sqlite') # This creates the database file\n",
    "grc_c = grc_conn.cursor() # Creates a cursor\n",
    "grc_c.execute(\"CREATE INDEX IF NOT EXISTS ngram_count_IN ON ngrams (ngram_size, total_grc_freq)\")\n",
    "grc_c.execute(\"CREATE INDEX IF NOT EXISTS ngram_count_fic_IN ON ngrams (ngram_size, total_grc_fic_freq)\")\n",
    "grc_conn.commit()\n",
    "\n",
    "print(\"creating indices\")\n",
    "grc_c.execute(\"CREATE INDEX IF NOT EXISTS ngrams_wordoneID_idx ON ngrams(wordoneID)\")\n",
    "grc_c.execute(\"CREATE INDEX IF NOT EXISTS ngrams_wordtwoID_idx ON ngrams(wordtwoID)\")\n",
    "grc_c.execute(\"CREATE INDEX IF NOT EXISTS ngrams_ngram_size_idx ON ngrams(ngram_size)\")\n",
    "grc_c.execute(\"CREATE INDEX IF NOT EXISTS corpus_word_typeID_idx ON corpus(word_typeID)\")\n",
    "grc_c.execute(\"CREATE INDEX IF NOT EXISTS corpus_f_nf_idx ON corpus(f_nf)\")\n",
    "grc_c.execute(\"CREATE INDEX IF NOT EXISTS corpus_erf_level_idx ON corpus(erf_level)\")\n",
    "grc_c.execute(\"CREATE INDEX IF NOT EXISTS corpus_file_id_idx ON corpus(file_id)\")\n",
    "grc_c.execute(\"CREATE INDEX corpus_f_nf_erf_level_idx ON corpus (f_nf, erf_level)\")\n",
    "grc_conn.commit()\n",
    "\n",
    "grc_conn.commit()\n",
    "\n",
    "print(\"updating total_grc_fic_freq\")\n",
    "grc_c.execute(\"\"\"UPDATE ngrams\n",
    "SET total_grc_fic_freq = (\n",
    "    SELECT COUNT(*) \n",
    "    FROM corpus\n",
    "    JOIN corpus AS corpus_2 ON corpus.file_id = corpus_2.file_id AND corpus.rowid + 1 = corpus_2.rowid\n",
    "    WHERE ngrams.wordoneID = corpus.word_typeID AND ngrams.wordtwoID = corpus_2.word_typeID\n",
    "    AND corpus.f_nf = 'F'\n",
    "    AND ngrams.ngram_size = 2)\"\"\"\n",
    ")\n",
    "\n",
    "print(\"updating erf_one_fic_freq\")\n",
    "grc_c.execute(\"\"\"UPDATE ngrams\n",
    "SET erf_one_fic_freq = (\n",
    "    SELECT COUNT(*)\n",
    "    FROM corpus\n",
    "    JOIN corpus AS corpus_2 ON corpus.file_id = corpus_2.file_id AND corpus.rowid + 1 = corpus_2.rowid\n",
    "    WHERE ngrams.wordoneID = corpus.word_typeID AND ngrams.wordtwoID = corpus_2.word_typeID\n",
    "    AND corpus.f_nf = 'F' AND corpus.erf_level = 1\n",
    "    AND ngrams.ngram_size = 2)\"\"\"\n",
    ")\n",
    "\n",
    "print(\"updating erf_two_fic_freq\")\n",
    "grc_c.execute(\"\"\"UPDATE ngrams\n",
    "SET erf_two_fic_freq = (\n",
    "    SELECT COUNT(*)\n",
    "    FROM corpus\n",
    "    JOIN corpus AS corpus_2 ON corpus.file_id = corpus_2.file_id AND corpus.rowid + 1 = corpus_2.rowid\n",
    "    WHERE ngrams.wordoneID = corpus.word_typeID AND ngrams.wordtwoID = corpus_2.word_typeID\n",
    "    AND corpus.f_nf = 'F' AND corpus.erf_level = 2\n",
    "    AND ngrams.ngram_size = 2)\"\"\"\n",
    ")\n",
    "\n",
    "print(\"updating erf_three_fic_freq\")\n",
    "grc_c.execute(\"\"\"UPDATE ngrams\n",
    "SET erf_three_fic_freq = (\n",
    "    SELECT COUNT(*)\n",
    "    FROM corpus\n",
    "    JOIN corpus AS corpus_2 ON corpus.file_id = corpus_2.file_id AND corpus.rowid + 1 = corpus_2.rowid\n",
    "    WHERE ngrams.wordoneID = corpus.word_typeID AND ngrams.wordtwoID = corpus_2.word_typeID\n",
    "    AND corpus.f_nf = 'F' AND corpus.erf_level = 3\n",
    "    AND ngrams.ngram_size = 2)\"\"\"\n",
    ")\n",
    "\n",
    "print(\"updating erf_four_fic_freq\")\n",
    "grc_c.execute(\"\"\"UPDATE ngrams\n",
    "SET erf_four_fic_freq = (\n",
    "    SELECT COUNT(*)\n",
    "    FROM corpus\n",
    "    JOIN corpus AS corpus_2 ON corpus.file_id = corpus_2.file_id AND corpus.rowid + 1 = corpus_2.rowid\n",
    "    WHERE ngrams.wordoneID = corpus.word_typeID AND ngrams.wordtwoID = corpus_2.word_typeID\n",
    "    AND corpus.f_nf = 'F' AND corpus.erf_level = 4\n",
    "    AND ngrams.ngram_size = 2)\"\"\"\n",
    ")\n",
    "\n",
    "print(\"updating erf_five_fic_freq\")\n",
    "grc_c.execute(\"\"\"UPDATE ngrams\n",
    "SET erf_five_fic_freq = (\n",
    "    SELECT COUNT(*)\n",
    "    FROM corpus\n",
    "    JOIN corpus AS corpus_2 ON corpus.file_id = corpus_2.file_id AND corpus.rowid + 1 = corpus_2.rowid\n",
    "    WHERE ngrams.wordoneID = corpus.word_typeID AND ngrams.wordtwoID = corpus_2.word_typeID\n",
    "    AND corpus.f_nf = 'F' AND corpus.erf_level = 5\n",
    "    AND ngrams.ngram_size = 2)\"\"\"\n",
    ")\n",
    "\n",
    "print(\"updating erf_six_fic_freq\")\n",
    "grc_c.execute(\"\"\"UPDATE ngrams\n",
    "SET erf_six_fic_freq = (\n",
    "    SELECT COUNT(*)\n",
    "    FROM corpus\n",
    "    JOIN corpus AS corpus_2 ON corpus.file_id = corpus_2.file_id AND corpus.rowid + 1 = corpus_2.rowid \n",
    "    WHERE ngrams.wordoneID = corpus.word_typeID AND ngrams.wordtwoID = corpus_2.word_typeID\n",
    "    AND corpus.f_nf = 'F' AND corpus.erf_level = 6\n",
    "    AND ngrams.ngram_size = 2)\"\"\"\n",
    ")\n",
    "\n",
    "grc_conn.commit()\n",
    "grc_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating indices: 2-gram\n",
      "creating indices: 3-gram\n",
      "creating indices: 4-gram\n",
      "creating indices: 5-gram\n",
      "writing RQ6_coca_tot_2gram.csv\n",
      "u.s. not found\n",
      "qwq not found\n",
      "amp not found\n",
      "@(off not found\n",
      "@(off not found\n",
      "@(footage not found\n",
      "@(voiceover not found\n",
      "@!unidentified not found\n",
      "writing RQ6_coca_tot_3gram.csv\n",
      "@(off not found\n",
      "u.s. not found\n",
      "writing RQ6_coca_tot_4gram.csv\n",
      "writing RQ6_coca_tot_5gram.csv\n",
      "writing RQ6_coca_fic_2gram.csv\n",
      "rsquo not found\n",
      "int not found\n",
      "writing RQ6_coca_fic_3gram.csv\n",
      "int not found\n",
      "writing RQ6_coca_fic_4gram.csv\n",
      "writing RQ6_coca_fic_5gram.csv\n"
     ]
    }
   ],
   "source": [
    "# producing keyness information for coca files\n",
    "\n",
    "import sqlite3, os\n",
    "\n",
    "# connect to the database\n",
    "if os.name == 'nt':  # 'nt' is the name for Windows in Python's os module\n",
    "    grc_conn = sqlite3.connect('D:\\\\graded_readers_mwe.sqlite')\n",
    "else:  # Assume Unix-based system (like macOS or Linux)\n",
    "    try:\n",
    "        grc_conn = sqlite3.connect('/Volumes/T7/graded_readers_mwe.sqlite')\n",
    "    except:\n",
    "        grc_conn = sqlite3.connect('/Volumes/KINGSTON/graded_readers_mwe.sqlite')\n",
    "\n",
    "grc_c = grc_conn.cursor() # Creates a cursor\n",
    "\n",
    "gramsizes = [(2,\"two\"),(3,\"three\"),(4,\"four\"),(5,\"five\")]\n",
    "genres = [\"tot\", \"fic\"] \n",
    "\n",
    "# creating indices\n",
    "print(\"creating indices: 2-gram\")\n",
    "grc_c.execute(\"\"\"CREATE INDEX IF NOT EXISTS twogram_search ON ngrams(ngram_size, wordoneID, wordtwoID)\"\"\")\n",
    "print(\"creating indices: 3-gram\")\n",
    "grc_c.execute(\"\"\"CREATE INDEX IF NOT EXISTS threegram_search ON ngrams(ngram_size, wordoneID, wordtwoID, wordthreeID)\"\"\")\n",
    "print(\"creating indices: 4-gram\")\n",
    "grc_c.execute(\"\"\"CREATE INDEX IF NOT EXISTS fourgram_search ON ngrams(ngram_size, wordoneID, wordtwoID, wordthreeID, wordfourID)\"\"\")\n",
    "print(\"creating indices: 5-gram\")\n",
    "grc_c.execute(\"\"\"CREATE INDEX IF NOT EXISTS fivegram_search ON ngrams(ngram_size, wordoneID, wordtwoID, wordthreeID, wordfourID, wordfiveID)\"\"\")\n",
    "grc_conn.commit()\n",
    "\n",
    "for genre in genres:\n",
    "    for num, text in gramsizes:\n",
    "        filename = \"RQ6_coca_\" + genre + \"_\" + str(num) + \"gram.csv\"\n",
    "        print(\"writing \" + filename)\n",
    "        filepath = os.path.join('Output', filename)\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            phrase_list = f.readlines()\n",
    "        output_filename = \"RQ6_coca_\" + genre + \"_\" + str(num) + \"gram_KEYNESS.csv\"\n",
    "        output_filepath = os.path.join('Output', output_filename)\n",
    "        with open(output_filepath, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"ngram, coca_freq, grc_freq\\n\")\n",
    "            counter = 0\n",
    "            for line in phrase_list:\n",
    "                counter += 1\n",
    "                if counter == 1:\n",
    "                    continue\n",
    "                line = line.split(\",\")\n",
    "                ngram = line[0].split(\"_\")\n",
    "                wordone = ngram[0].lower()\n",
    "                try:\n",
    "                    wordoneID = grc_c.execute(\"\"\"SELECT ID FROM lexicon WHERE type_lc = ?\"\"\", (wordone,)).fetchone()[0]\n",
    "                except:\n",
    "                    print(ngram[0].lower(), \"not found\")\n",
    "                    wordone = \"ERROR\"\n",
    "                wordtwo = ngram[1].lower()\n",
    "                try:\n",
    "                    wordtwoID = grc_c.execute(\"\"\"SELECT ID FROM lexicon WHERE type_lc = ?\"\"\", (wordtwo,)).fetchone()[0]\n",
    "                except:\n",
    "                    print(ngram[1].lower(), \"not found\")\n",
    "                    wordtwo = \"ERROR\"\n",
    "                query_string = \"\"\"wordoneID = ? AND wordtwoID = ?\"\"\"\n",
    "                if num >= 3:\n",
    "                    wordthree = ngram[2].lower()\n",
    "                    try:\n",
    "                        wordthreeID = grc_c.execute(\"\"\"SELECT ID FROM lexicon WHERE type_lc = ?\"\"\", (wordthree,)).fetchone()[0]\n",
    "                    except:\n",
    "                        print(ngram[2].lower(), \"not found\")\n",
    "                        wordthree = \"ERROR\"\n",
    "                    query_string = \"\"\"wordoneID = ? AND wordtwoID = ? AND wordthreeID = ?\"\"\"\n",
    "                if num >= 4:\n",
    "                    wordfour = ngram[3].lower()\n",
    "                    try:\n",
    "                        wordfourID = grc_c.execute(\"\"\"SELECT ID FROM lexicon WHERE type_lc = ?\"\"\", (wordfour,)).fetchone()[0]\n",
    "                    except:\n",
    "                        print(ngram[3].lower(), \"not found\")\n",
    "                        wordfour = \"ERROR\"\n",
    "                    query_string = \"\"\"wordoneID = ? AND wordtwoID = ? AND wordthreeID = ? AND wordfourID = ?\"\"\"\n",
    "                if num == 5:\n",
    "                    wordfive = ngram[4].lower()\n",
    "                    try:\n",
    "                        wordfiveID = grc_c.execute(\"\"\"SELECT ID FROM lexicon WHERE type_lc = ?\"\"\", (wordfive,)).fetchone()[0]\n",
    "                    except:\n",
    "                        print(ngram[4].lower(), \"not found\")\n",
    "                        wordfive = \"ERROR\"\n",
    "                    query_string = \"\"\"wordoneID = ? AND wordtwoID = ? AND wordthreeID = ? AND wordfourID = ? AND wordfiveID = ?\"\"\"\n",
    "                freq = line[1]\n",
    "                if genre == \"tot\":\n",
    "                    query = \"\"\"SELECT total_grc_freq\n",
    "                            FROM ngrams\n",
    "                            WHERE ngram_size = ? AND \"\"\" + query_string\n",
    "                else:\n",
    "                    query = \"\"\"SELECT total_grc_fic_freq\n",
    "                            FROM ngrams\n",
    "                            WHERE ngram_size = ? AND \"\"\" + query_string\n",
    "                if num == 2:\n",
    "                    grc_c.execute(query, (num, wordoneID, wordtwoID))\n",
    "                elif num == 3:\n",
    "                    grc_c.execute(query, (num, wordoneID, wordtwoID, wordthreeID))\n",
    "                elif num == 4:\n",
    "                    grc_c.execute(query, (num, wordoneID, wordtwoID, wordthreeID, wordfourID))\n",
    "                elif num == 5:\n",
    "                    grc_c.execute(query, (num, wordoneID, wordtwoID, wordthreeID, wordfourID, wordfiveID))\n",
    "                try:\n",
    "                    grc_freq = str(grc_c.fetchone()[0])\n",
    "                except:\n",
    "                    grc_freq = \"0\"\n",
    "                f.write(line[0] + \",\" + freq.strip(\"\\n\") + \",\" + grc_freq + \"\\n\")\n",
    "\n",
    "grc_conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 26\u001b[0m\n\u001b[1;32m     19\u001b[0m type_2 \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrights\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     21\u001b[0m grc_c\u001b[39m.\u001b[39mexecute(\u001b[39m\"\"\"\u001b[39m\u001b[39mSELECT L1.rowid \u001b[39m\n\u001b[1;32m     22\u001b[0m \u001b[39m                FROM corpus_table AS L1\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[39m                JOIN corpus_table AS L2 \u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[39m                    ON L1.rowid = L2.rowid - 1\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[39m                WHERE L1.type_lc = ? AND L2.type_lc = ?\u001b[39m\u001b[39m\"\"\"\u001b[39m, (type_1, type_2))\n\u001b[0;32m---> 26\u001b[0m rowid \u001b[39m=\u001b[39m grc_c\u001b[39m.\u001b[39;49mfetchone()[\u001b[39m0\u001b[39;49m]\n\u001b[1;32m     28\u001b[0m grc_c\u001b[39m.\u001b[39mexecute(\u001b[39m\"\"\"\u001b[39m\u001b[39mSELECT type_lc, publisher, title, erf_level FROM corpus_table WHERE rowid BETWEEN ? AND ?\u001b[39m\u001b[39m\"\"\"\u001b[39m, (rowid \u001b[39m-\u001b[39m \u001b[39m20\u001b[39m, rowid \u001b[39m+\u001b[39m \u001b[39m20\u001b[39m))\n\u001b[1;32m     29\u001b[0m lines \u001b[39m=\u001b[39m grc_c\u001b[39m.\u001b[39mfetchall()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import sqlite3, os\n",
    "\n",
    "# connect to the database\n",
    "if os.name == 'nt':  # 'nt' is the name for Windows in Python's os module\n",
    "    grc_conn = sqlite3.connect('D:\\\\graded_readers_mwe.sqlite')\n",
    "else:  # Assume Unix-based system (like macOS or Linux)\n",
    "    try:\n",
    "        grc_conn = sqlite3.connect('/Volumes/T7/0a_graded_readers.sqlite')\n",
    "    except:\n",
    "        grc_conn = sqlite3.connect('/Volumes/KINGSTON/0a_graded_readers.sqlite')\n",
    "\n",
    "grc_c = grc_conn.cursor() # Creates a cursor\n",
    "\n",
    "# search the two_grams view for type_1 and type_2\n",
    "# return the 10 lines before and 10 lines after\n",
    "# print the lines\n",
    "\n",
    "type_1 = \"all\"\n",
    "type_2 = \"rights\"\n",
    "\n",
    "grc_c.execute(\"\"\"SELECT L1.rowid \n",
    "                FROM corpus_table AS L1\n",
    "                JOIN corpus_table AS L2 \n",
    "                    ON L1.rowid = L2.rowid - 1\n",
    "                WHERE L1.type_lc = ? AND L2.type_lc = ?\"\"\", (type_1, type_2))\n",
    "rowid = grc_c.fetchone()[0]\n",
    "\n",
    "grc_c.execute(\"\"\"SELECT type_lc, publisher, title, erf_level FROM corpus_table WHERE rowid BETWEEN ? AND ?\"\"\", (rowid - 20, rowid + 20))\n",
    "lines = grc_c.fetchall()\n",
    "\n",
    "for line in lines:\n",
    "    print(line)\n",
    "\n",
    "\n",
    "grc_conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
